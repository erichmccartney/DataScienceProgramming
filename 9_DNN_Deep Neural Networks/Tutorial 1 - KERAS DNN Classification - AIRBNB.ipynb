{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1 - KERAS DNN Classification\n",
    "\n",
    "We will predict the price category, among 4 categories, of an AIRBNB listing (`price_category` column). This is a multi-class classification task.\n",
    "\n",
    "**The unit of analysis is an AIRBNB LISTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>neighbourhood_cleansed</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>price_per_extra_person</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>number_days_btw_first_last_review</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>price</th>\n",
       "      <th>price_gte_150</th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.282619</td>\n",
       "      <td>-71.133068</td>\n",
       "      <td>House</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>moderate</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.286241</td>\n",
       "      <td>-71.134374</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>804</td>\n",
       "      <td>94.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.292438</td>\n",
       "      <td>-71.135765</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>2574</td>\n",
       "      <td>98.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.281106</td>\n",
       "      <td>-71.121021</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>lte_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roslindale</td>\n",
       "      <td>42.284512</td>\n",
       "      <td>-71.136258</td>\n",
       "      <td>House</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>380</td>\n",
       "      <td>99.0</td>\n",
       "      <td>flexible</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_identity_verified neighbourhood_cleansed  \\\n",
       "0                  0                       0             Roslindale   \n",
       "1                  0                       1             Roslindale   \n",
       "2                  1                       1             Roslindale   \n",
       "3                  0                       0             Roslindale   \n",
       "4                  1                       1             Roslindale   \n",
       "\n",
       "    latitude  longitude property_type        room_type  accommodates  \\\n",
       "0  42.282619 -71.133068         House  Entire home/apt             4   \n",
       "1  42.286241 -71.134374     Apartment     Private room             2   \n",
       "2  42.292438 -71.135765     Apartment     Private room             2   \n",
       "3  42.281106 -71.121021         House     Private room             4   \n",
       "4  42.284512 -71.136258         House     Private room             2   \n",
       "\n",
       "   bathrooms  bedrooms  ...  guests_included price_per_extra_person  \\\n",
       "0        1.5       2.0  ...                1                      0   \n",
       "1        1.0       1.0  ...                0                      0   \n",
       "2        1.0       1.0  ...                1                     20   \n",
       "3        1.0       1.0  ...                2                     25   \n",
       "4        1.5       1.0  ...                1                      0   \n",
       "\n",
       "   minimum_nights  number_of_reviews  number_days_btw_first_last_review  \\\n",
       "0               2                  0                                  0   \n",
       "1               2                 36                                804   \n",
       "2               3                 41                               2574   \n",
       "3               1                  1                                  0   \n",
       "4               2                 29                                380   \n",
       "\n",
       "   review_scores_rating  cancellation_policy  price  price_gte_150  \\\n",
       "0                   NaN             moderate    250              1   \n",
       "1                  94.0             moderate     65              0   \n",
       "2                  98.0             moderate     65              0   \n",
       "3                 100.0             moderate     75              0   \n",
       "4                  99.0             flexible     79              0   \n",
       "\n",
       "  price_category  \n",
       "0        gte_226  \n",
       "1         lte_75  \n",
       "2         lte_75  \n",
       "3         lte_75  \n",
       "4     btw_75-150  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price_gte_150\" value in the data set:\n",
    "\n",
    "airbnb = pd.read_csv(\"airbnb.csv\")\n",
    "airbnb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(airbnb, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Be careful: we haven't seperated the target column yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                       0\n",
       "host_identity_verified                  0\n",
       "neighbourhood_cleansed                  0\n",
       "latitude                                0\n",
       "longitude                               0\n",
       "property_type                           8\n",
       "room_type                               0\n",
       "accommodates                            0\n",
       "bathrooms                              19\n",
       "bedrooms                               19\n",
       "beds                                   16\n",
       "bed_type                                0\n",
       "Number of amenities                     0\n",
       "guests_included                         0\n",
       "price_per_extra_person                  0\n",
       "minimum_nights                          0\n",
       "number_of_reviews                       0\n",
       "number_days_btw_first_last_review       0\n",
       "review_scores_rating                 1609\n",
       "cancellation_policy                     0\n",
       "price                                   0\n",
       "price_gte_150                           0\n",
       "price_category                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                      0\n",
       "host_identity_verified                 0\n",
       "neighbourhood_cleansed                 0\n",
       "latitude                               0\n",
       "longitude                              0\n",
       "property_type                          1\n",
       "room_type                              0\n",
       "accommodates                           0\n",
       "bathrooms                             17\n",
       "bedrooms                              11\n",
       "beds                                   8\n",
       "bed_type                               0\n",
       "Number of amenities                    0\n",
       "guests_included                        0\n",
       "price_per_extra_person                 0\n",
       "minimum_nights                         0\n",
       "number_of_reviews                      0\n",
       "number_days_btw_first_last_review      0\n",
       "review_scores_rating                 674\n",
       "cancellation_policy                    0\n",
       "price                                  0\n",
       "price_gte_150                          0\n",
       "price_category                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the variables we can't use in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial, because they are not for binary classification tasks\n",
    "\n",
    "train = train_set.drop(['price', 'price_gte_150'], axis=1)\n",
    "test = test_set.drop(['price', 'price_gte_150'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train[['price_category']]\n",
    "test_target = test[['price_category']]\n",
    "\n",
    "train_inputs = train.drop(['price_category'], axis=1)\n",
    "test_inputs = test.drop(['price_category'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remember, the \"minimum_nights\" column is highly skewed. Let's try to transform it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      2901\n",
       "2      1980\n",
       "3      1220\n",
       "7       254\n",
       "4       239\n",
       "5       185\n",
       "10      144\n",
       "30       57\n",
       "14       50\n",
       "15       43\n",
       "6        35\n",
       "20       15\n",
       "28       13\n",
       "32        9\n",
       "25        8\n",
       "60        6\n",
       "90        5\n",
       "27        4\n",
       "9         4\n",
       "17        3\n",
       "13        3\n",
       "23        3\n",
       "8         2\n",
       "21        2\n",
       "11        2\n",
       "273       2\n",
       "18        1\n",
       "Name: minimum_nights, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_inputs['minimum_nights'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import power transformer from sklearn. It will help us create a \"normal distribution\"\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "PT = PowerTransformer(method = 'yeo-johnson', standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_min_nights = PT.fit_transform(train_inputs[['minimum_nights']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_min_nights).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE1: We didn't make the transformed variable as part of the input variables yet. To do that, we will use the pipeline.\n",
    "\n",
    "NOTE2: We don't need to create a function (like before). This transformer already has fit() and transform(). So, we can use this in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Identify the numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_is_superhost                      int64\n",
       "host_identity_verified                 int64\n",
       "neighbourhood_cleansed                object\n",
       "latitude                             float64\n",
       "longitude                            float64\n",
       "property_type                         object\n",
       "room_type                             object\n",
       "accommodates                           int64\n",
       "bathrooms                            float64\n",
       "bedrooms                             float64\n",
       "beds                                 float64\n",
       "bed_type                              object\n",
       "Number of amenities                    int64\n",
       "guests_included                        int64\n",
       "price_per_extra_person                 int64\n",
       "minimum_nights                         int64\n",
       "number_of_reviews                      int64\n",
       "number_days_btw_first_last_review      int64\n",
       "review_scores_rating                 float64\n",
       "cancellation_policy                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this stage, you can manually identify numeric, binary, and categorical columns as follows:**\n",
    "\n",
    "`numeric_columns = ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'Number of amenities', 'guests_included', 'price_per_extra_person', 'minimum_nights', 'number_of_reviews', 'number_days_btw_first_last_review', 'review_scores_rating']`\n",
    " \n",
    " `binary_columns = ['host_is_superhost', 'host_identity_verified']`\n",
    " \n",
    " `categorical_columns = ['neighbourhood_cleansed', 'property_type', 'room_type', 'bed_type', 'cancellation_policy']`\n",
    " \n",
    "<br>\n",
    " \n",
    "**If you do not want to manually type these, you can do the below tricks:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['host_is_superhost', 'host_identity_verified']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'Number of amenities',\n",
       " 'guests_included',\n",
       " 'price_per_extra_person',\n",
       " 'minimum_nights',\n",
       " 'number_of_reviews',\n",
       " 'number_days_btw_first_last_review',\n",
       " 'review_scores_rating']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neighbourhood_cleansed',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'bed_type',\n",
       " 'cancellation_policy']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['minimum_nights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('powertransformer', PowerTransformer(method = 'yeo-johnson', standardize=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, transformed_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.10940159, -1.39824237,  1.20477863, ...,  0.        ,\n",
       "         1.        ,  0.21001201],\n",
       "       [ 0.61906783, -1.38593382, -1.16133947, ...,  0.        ,\n",
       "         0.        ,  2.02534721],\n",
       "       [ 0.14448465, -0.16705969, -1.16133947, ...,  0.        ,\n",
       "         1.        ,  0.21001201],\n",
       "       ...,\n",
       "       [ 0.82039585,  0.74441303, -0.56980994, ...,  0.        ,\n",
       "         0.        ,  1.372366  ],\n",
       "       [-0.92762441,  0.3821493 , -0.56980994, ...,  0.        ,\n",
       "         1.        , -1.08388465],\n",
       "       [-0.34071414, -0.53929512, -1.16133947, ...,  0.        ,\n",
       "         0.        , -1.08388465]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7190, 62)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63069768,  0.40533687,  1.79630816, ...,  0.        ,\n",
       "         1.        ,  0.81147266],\n",
       "       [ 0.15153485,  0.27611111, -0.56980994, ...,  0.        ,\n",
       "         1.        ,  1.63309414],\n",
       "       [-2.02789334, -0.91924215,  0.02171958, ...,  0.        ,\n",
       "         1.        ,  0.21001201],\n",
       "       ...,\n",
       "       [ 0.15906806, -0.38872897,  1.20477863, ...,  0.        ,\n",
       "         1.        ,  0.81147266],\n",
       "       [ 0.11838687, -0.56878308, -0.56980994, ...,  0.        ,\n",
       "         0.        , -1.08388465],\n",
       "       [-0.94171792,  0.19283558, -1.16133947, ...,  0.        ,\n",
       "         1.        ,  2.13904414]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3082, 62)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6622</th>\n",
       "      <td>lte_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>gte_226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>btw_75-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>lte_75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7190 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price_category\n",
       "3437     btw_75-150\n",
       "6622         lte_75\n",
       "2262     btw_75-150\n",
       "2246     btw_75-150\n",
       "835         gte_226\n",
       "...             ...\n",
       "5734        gte_226\n",
       "5191     btw_75-150\n",
       "5390        gte_226\n",
       "860      btw_75-150\n",
       "7270         lte_75\n",
       "\n",
       "[7190 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras needs Ordinal target values for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ord_enc = OrdinalEncoder()\n",
    "\n",
    "train_y = ord_enc.fit_transform(train_target)\n",
    "\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       ...,\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [3.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = ord_enc.transform(test_target)\n",
    "\n",
    "test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['btw_151-225', 'btw_75-150', 'gte_226', 'lte_75'], dtype=object)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_category\n",
       "btw_75-150        0.332823\n",
       "btw_151-225       0.241725\n",
       "lte_75            0.214743\n",
       "gte_226           0.210709\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target.value_counts()/len(train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification using Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7190, 62)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=62)) #match nerons with column count or train shape (train_x.shape[1])\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               6300      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 26,904\n",
      "Trainable params: 26,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal target (as in this example):\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **sparse_categorical_crossentropy**\n",
    "\n",
    "## One-hot target\n",
    "\n",
    "Final layer's activation = **softmax** <br>\n",
    "loss = **categorical_crossentropy**\n",
    "\n",
    "## Binary target \n",
    "\n",
    "Final layer has only 1 neuron <br>\n",
    "Final layer's activation = **sigmoid** <br>\n",
    "loss = **binary_crossentropy**\n",
    "\n",
    "## Regression task (target is continuous)\n",
    "\n",
    "Final layer has only 1 neuron (keras.layers.Dense(1))<br>\n",
    "Activation is None<br>\n",
    "loss = **mean_squared_error**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7732 - val_loss: 0.5939 - val_accuracy: 0.7547\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5248 - accuracy: 0.7750 - val_loss: 0.5926 - val_accuracy: 0.7554\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7754 - val_loss: 0.5829 - val_accuracy: 0.7638\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7782 - val_loss: 0.5821 - val_accuracy: 0.7592\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7786 - val_loss: 0.5816 - val_accuracy: 0.7641\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.7757 - val_loss: 0.5913 - val_accuracy: 0.7599\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7759 - val_loss: 0.5830 - val_accuracy: 0.7557\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5134 - accuracy: 0.7822 - val_loss: 0.5724 - val_accuracy: 0.7674\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7823 - val_loss: 0.5753 - val_accuracy: 0.7628\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7844 - val_loss: 0.5700 - val_accuracy: 0.7618\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5111 - accuracy: 0.7854 - val_loss: 0.5789 - val_accuracy: 0.7602\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.7830 - val_loss: 0.5686 - val_accuracy: 0.7696\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7896 - val_loss: 0.5723 - val_accuracy: 0.7635\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5080 - accuracy: 0.7869 - val_loss: 0.5680 - val_accuracy: 0.7683\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7848 - val_loss: 0.5646 - val_accuracy: 0.7755\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7928 - val_loss: 0.5577 - val_accuracy: 0.7716\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7833 - val_loss: 0.5572 - val_accuracy: 0.7657\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7898 - val_loss: 0.5637 - val_accuracy: 0.7680\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7865 - val_loss: 0.5699 - val_accuracy: 0.7719\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7983 - val_loss: 0.5543 - val_accuracy: 0.7758\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34639641642570496, 0.9130434989929199]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.35\n",
      "accuracy: 91.30%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send all inputs to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "\n",
    "inputlayer = keras.layers.Input(shape=62)\n",
    "\n",
    "hidden1 = keras.layers.Dense(100, activation='relu')(inputlayer)\n",
    "hidden2 = keras.layers.Dense(100, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(100, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([inputlayer, hidden3])\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(concat)\n",
    "\n",
    "model = keras.Model(inputs =[inputlayer], outputs = output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0153 - accuracy: 0.5170 - val_loss: 0.8469 - val_accuracy: 0.6087\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7976 - accuracy: 0.6360 - val_loss: 0.7898 - val_accuracy: 0.6402\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.6734 - val_loss: 0.7297 - val_accuracy: 0.6781\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.7086 - val_loss: 0.7268 - val_accuracy: 0.6924\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.7309 - val_loss: 0.6719 - val_accuracy: 0.6992\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5556 - accuracy: 0.7627 - val_loss: 0.6133 - val_accuracy: 0.7489\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7987 - val_loss: 0.5788 - val_accuracy: 0.7716\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8378 - val_loss: 0.5625 - val_accuracy: 0.7781\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8542 - val_loss: 0.5649 - val_accuracy: 0.8027\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8666 - val_loss: 0.5129 - val_accuracy: 0.8215\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8905 - val_loss: 0.4549 - val_accuracy: 0.8384\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.9086 - val_loss: 0.4608 - val_accuracy: 0.8469\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9157 - val_loss: 0.4991 - val_accuracy: 0.8511\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9298 - val_loss: 0.4336 - val_accuracy: 0.8783\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9420 - val_loss: 0.4236 - val_accuracy: 0.8851\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1580 - accuracy: 0.9395 - val_loss: 0.4204 - val_accuracy: 0.8858\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9495 - val_loss: 0.3992 - val_accuracy: 0.8952\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1482 - accuracy: 0.9460 - val_loss: 0.4854 - val_accuracy: 0.8835\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9462 - val_loss: 0.4264 - val_accuracy: 0.9017\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9542 - val_loss: 0.3935 - val_accuracy: 0.9079\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.39345189929008484, 0.907852053642273]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.39\n",
      "accuracy: 90.79%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's send two inputs to the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.10940159, -1.39824237],\n",
       "       [ 0.61906783, -1.38593382],\n",
       "       [ 0.14448465, -0.16705969],\n",
       "       ...,\n",
       "       [ 0.82039585,  0.74441303],\n",
       "       [-0.92762441,  0.3821493 ],\n",
       "       [-0.34071414, -0.53929512]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the first two columns: longitude and latitude\n",
    "#(WHY: because lat and lon are good and important predictors)\n",
    "\n",
    "lon_lat = train_x[:,:2]\n",
    "\n",
    "lon_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "input1 = keras.layers.Input(shape=2)\n",
    "input2 = keras.layers.Input(shape=62)\n",
    "\n",
    "hidden1 = keras.layers.Dense(100, activation='relu')(input2)\n",
    "hidden2 = keras.layers.Dense(100, activation='relu')(hidden1)\n",
    "hidden3 = keras.layers.Dense(100, activation='relu')(hidden2)\n",
    "\n",
    "concat = keras.layers.Concatenate()([input1, hidden3])\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(concat)\n",
    "\n",
    "model = keras.Model(inputs =[input1, input2], outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 7ms/step - loss: 1.0083 - accuracy: 0.5285 - val_loss: 0.8429 - val_accuracy: 0.6142\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7968 - accuracy: 0.6307 - val_loss: 0.7881 - val_accuracy: 0.6531\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7312 - accuracy: 0.6658 - val_loss: 0.7440 - val_accuracy: 0.6690\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6706 - accuracy: 0.7015 - val_loss: 0.7103 - val_accuracy: 0.7021\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.7387 - val_loss: 0.6693 - val_accuracy: 0.7187\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7830 - val_loss: 0.5849 - val_accuracy: 0.7573\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4414 - accuracy: 0.8210 - val_loss: 0.5784 - val_accuracy: 0.7592\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8381 - val_loss: 0.5484 - val_accuracy: 0.7842\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8659 - val_loss: 0.5476 - val_accuracy: 0.7914\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8776 - val_loss: 0.4737 - val_accuracy: 0.8332\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.9074 - val_loss: 0.4407 - val_accuracy: 0.8446\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2354 - accuracy: 0.9060 - val_loss: 0.3886 - val_accuracy: 0.8689\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9357 - val_loss: 0.4324 - val_accuracy: 0.8621\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9380 - val_loss: 0.3609 - val_accuracy: 0.8923\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 0.9509 - val_loss: 0.4105 - val_accuracy: 0.8832\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9530 - val_loss: 0.3576 - val_accuracy: 0.9046\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9577 - val_loss: 0.3719 - val_accuracy: 0.9117\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9586 - val_loss: 0.3902 - val_accuracy: 0.9072\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9581 - val_loss: 0.3985 - val_accuracy: 0.9062\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9611 - val_loss: 0.3454 - val_accuracy: 0.9127\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit((lon_lat, train_x), train_y, \n",
    "                    validation_data=((test_x[:,:2], test_x), test_y), \n",
    "                    epochs=20, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3454035818576813, 0.9127190113067627]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate((test_x[:,:2], test_x), test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.35\n",
      "accuracy: 91.27%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers, Learning rate, Dropout, Initialization & Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "\n",
    "#Set the learning rate:\n",
    "lr=0.001\n",
    "\n",
    "\n",
    "#Available optimizers:\n",
    "adagrad = keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=0.0)\n",
    "sgd = keras.optimizers.SGD(lr=lr, momentum=0.0, decay=0.0, nesterov=False)\n",
    "rmsprop = keras.optimizers.RMSprop(lr=lr, rho=0.9, epsilon=None, decay=0.0)\n",
    "adam = keras.optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "nesterov_adam = keras.optimizers.Nadam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "#Initializations:\n",
    "xavier = keras.initializers.glorot_normal(seed=None)\n",
    "he = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "\n",
    "# Activation functions. Uncomment only one\n",
    "activation = 'elu' \n",
    "#activation = 'relu'\n",
    "#activation = 'tanh'\n",
    "#activation = 'sigmoid'\n",
    "\n",
    "\n",
    "\n",
    "#See the droput layers below:\n",
    "input1 = keras.layers.Input(shape=62)\n",
    "\n",
    "hidden1 = keras.layers.Dense(100, activation=activation, kernel_initializer=xavier)(input1)\n",
    "drop1   = keras.layers.Dropout(0.2)(hidden1)\n",
    "hidden2 = keras.layers.Dense(100, activation=activation, kernel_initializer=xavier)(drop1)\n",
    "drop2   = keras.layers.Dropout(0.2)(hidden2)\n",
    "hidden3 = keras.layers.Dense(100, activation=activation, kernel_initializer=xavier)(drop2)\n",
    "\n",
    "#final layer: there has to be 4 nodes with softmax (because we have 4 categories)\n",
    "output = keras.layers.Dense(4, activation='softmax')(hidden3)\n",
    "\n",
    "#Compile\"\n",
    "model = keras.Model(inputs = input1, outputs = output)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=nesterov_adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 0s 8ms/step - loss: 1.2289 - accuracy: 0.4210 - val_loss: 1.0037 - val_accuracy: 0.5548\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9926 - accuracy: 0.5476 - val_loss: 0.9122 - val_accuracy: 0.5850\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.9265 - accuracy: 0.5723 - val_loss: 0.8702 - val_accuracy: 0.6113\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8963 - accuracy: 0.5880 - val_loss: 0.8513 - val_accuracy: 0.6132\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8757 - accuracy: 0.5978 - val_loss: 0.8385 - val_accuracy: 0.6201\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8643 - accuracy: 0.6022 - val_loss: 0.8288 - val_accuracy: 0.6243\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.6088 - val_loss: 0.8189 - val_accuracy: 0.6366\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8444 - accuracy: 0.6170 - val_loss: 0.8108 - val_accuracy: 0.6415\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8382 - accuracy: 0.6220 - val_loss: 0.8107 - val_accuracy: 0.6337\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8311 - accuracy: 0.6267 - val_loss: 0.8012 - val_accuracy: 0.6444\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.6225 - val_loss: 0.8014 - val_accuracy: 0.6447\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8275 - accuracy: 0.6197 - val_loss: 0.8058 - val_accuracy: 0.6395\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8128 - accuracy: 0.6309 - val_loss: 0.8123 - val_accuracy: 0.6330\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8234 - accuracy: 0.6267 - val_loss: 0.7964 - val_accuracy: 0.6424\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8097 - accuracy: 0.6325 - val_loss: 0.7950 - val_accuracy: 0.6460\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8061 - accuracy: 0.6346 - val_loss: 0.7884 - val_accuracy: 0.6522\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8027 - accuracy: 0.6381 - val_loss: 0.7949 - val_accuracy: 0.6421\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.6334 - val_loss: 0.7945 - val_accuracy: 0.6486\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7976 - accuracy: 0.6307 - val_loss: 0.8076 - val_accuracy: 0.6334\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7948 - accuracy: 0.6405 - val_loss: 0.7889 - val_accuracy: 0.6441\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(train_x, train_y, \n",
    "                    validation_data=(test_x, test_y), \n",
    "                    epochs=20, batch_size=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7889317274093628, 0.6440622806549072]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.79\n",
      "accuracy: 64.41%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early stopping based on validation results\n",
    "\n",
    "To do this, you need to send the validation data sets to the fit() function and use a callback.\n",
    "\n",
    "EarlyStopping Arguments:\n",
    "\n",
    "**monitor:** quantity to be monitored.<br>\n",
    "**min_delta:** minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta, will count as no improvement.<br>\n",
    "**patience:** number of epochs with no improvement after which training will be stopped.<br>\n",
    "**verbose:** verbosity mode.<br>\n",
    "**mode:** one of {auto, min, max}. In min mode, training will stop when the quantity monitored has stopped decreasing; in max mode it will stop when the quantity monitored has stopped increasing; in auto mode, the direction is automatically inferred from the name of the monitored quantity.<br>\n",
    "**baseline:** Baseline value for the monitored quantity to reach. Training will stop if the model doesn't show improvement over the baseline.<br>\n",
    "**restore_best_weights:** whether to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.7912 - accuracy: 0.6431 - val_loss: 0.7901 - val_accuracy: 0.6457\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7924 - accuracy: 0.6480 - val_loss: 0.7869 - val_accuracy: 0.6515\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7846 - accuracy: 0.6441 - val_loss: 0.7820 - val_accuracy: 0.6577\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7855 - accuracy: 0.6426 - val_loss: 0.7785 - val_accuracy: 0.6515\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7796 - accuracy: 0.6410 - val_loss: 0.7789 - val_accuracy: 0.6506\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7749 - accuracy: 0.6478 - val_loss: 0.7879 - val_accuracy: 0.6548\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.6508 - val_loss: 0.7759 - val_accuracy: 0.6577\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.6573 - val_loss: 0.7695 - val_accuracy: 0.6639\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7677 - accuracy: 0.6563 - val_loss: 0.7743 - val_accuracy: 0.6626\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.6590 - val_loss: 0.7651 - val_accuracy: 0.6684\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7651 - accuracy: 0.6579 - val_loss: 0.7640 - val_accuracy: 0.6635\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.6530 - val_loss: 0.7744 - val_accuracy: 0.6616\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.6641 - val_loss: 0.7762 - val_accuracy: 0.6528\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.6567 - val_loss: 0.7601 - val_accuracy: 0.6668\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.6655 - val_loss: 0.7649 - val_accuracy: 0.6593\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.6677 - val_loss: 0.7557 - val_accuracy: 0.6739\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.6648 - val_loss: 0.7626 - val_accuracy: 0.6616\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.6704 - val_loss: 0.7595 - val_accuracy: 0.6655\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.6715 - val_loss: 0.7766 - val_accuracy: 0.6548\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7418 - accuracy: 0.6650 - val_loss: 0.7512 - val_accuracy: 0.6665\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7293 - accuracy: 0.6743 - val_loss: 0.7461 - val_accuracy: 0.6765\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.6713 - val_loss: 0.7430 - val_accuracy: 0.6742\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.6776 - val_loss: 0.7470 - val_accuracy: 0.6690\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.6740 - val_loss: 0.7458 - val_accuracy: 0.6697\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.6759 - val_loss: 0.7395 - val_accuracy: 0.6759\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7151 - accuracy: 0.6782 - val_loss: 0.7391 - val_accuracy: 0.6749\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7155 - accuracy: 0.6797 - val_loss: 0.7363 - val_accuracy: 0.6726\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7098 - accuracy: 0.6828 - val_loss: 0.7383 - val_accuracy: 0.6785\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7093 - accuracy: 0.6836 - val_loss: 0.7375 - val_accuracy: 0.6781\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.6840 - val_loss: 0.7279 - val_accuracy: 0.6785\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7088 - accuracy: 0.6851 - val_loss: 0.7254 - val_accuracy: 0.6859\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.6889 - val_loss: 0.7222 - val_accuracy: 0.6914\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.6911 - val_loss: 0.7228 - val_accuracy: 0.6853\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.6932 - val_loss: 0.7231 - val_accuracy: 0.6875\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.6930 - val_loss: 0.7234 - val_accuracy: 0.6901\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6864 - accuracy: 0.6962 - val_loss: 0.7326 - val_accuracy: 0.6853\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6865 - accuracy: 0.6950 - val_loss: 0.7138 - val_accuracy: 0.6879\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6786 - accuracy: 0.6974 - val_loss: 0.7182 - val_accuracy: 0.6944\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.6955 - val_loss: 0.7057 - val_accuracy: 0.6901\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.7011 - val_loss: 0.7087 - val_accuracy: 0.6992\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6749 - accuracy: 0.7024 - val_loss: 0.7105 - val_accuracy: 0.6976\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.7021 - val_loss: 0.7037 - val_accuracy: 0.6911\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6665 - accuracy: 0.7079 - val_loss: 0.7238 - val_accuracy: 0.6911\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.7089 - val_loss: 0.7061 - val_accuracy: 0.7005\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.7103 - val_loss: 0.7084 - val_accuracy: 0.6992\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.7083 - val_loss: 0.7088 - val_accuracy: 0.7025\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.7124 - val_loss: 0.7037 - val_accuracy: 0.6966\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.7131 - val_loss: 0.6935 - val_accuracy: 0.7034\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.7100 - val_loss: 0.6898 - val_accuracy: 0.7099\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.7140 - val_loss: 0.6916 - val_accuracy: 0.7051\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.7097 - val_loss: 0.6877 - val_accuracy: 0.7060\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6384 - accuracy: 0.7206 - val_loss: 0.6852 - val_accuracy: 0.7096\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6428 - accuracy: 0.7166 - val_loss: 0.6904 - val_accuracy: 0.7041\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6417 - accuracy: 0.7118 - val_loss: 0.6892 - val_accuracy: 0.6979\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.7125 - val_loss: 0.6713 - val_accuracy: 0.7141\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.7239 - val_loss: 0.6771 - val_accuracy: 0.7077\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7214 - val_loss: 0.6780 - val_accuracy: 0.7128\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6307 - accuracy: 0.7200 - val_loss: 0.6701 - val_accuracy: 0.7154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.7339 - val_loss: 0.6764 - val_accuracy: 0.7038\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7303 - val_loss: 0.6662 - val_accuracy: 0.7161\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6105 - accuracy: 0.7385 - val_loss: 0.6716 - val_accuracy: 0.7138\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6176 - accuracy: 0.7307 - val_loss: 0.6695 - val_accuracy: 0.7122\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6190 - accuracy: 0.7317 - val_loss: 0.6644 - val_accuracy: 0.7229\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6146 - accuracy: 0.7307 - val_loss: 0.6676 - val_accuracy: 0.7171\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6106 - accuracy: 0.7337 - val_loss: 0.6599 - val_accuracy: 0.7216\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.7339 - val_loss: 0.6593 - val_accuracy: 0.7213\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6099 - accuracy: 0.7341 - val_loss: 0.6556 - val_accuracy: 0.7219\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6066 - accuracy: 0.7427 - val_loss: 0.6536 - val_accuracy: 0.7203\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6039 - accuracy: 0.7424 - val_loss: 0.6535 - val_accuracy: 0.7206\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.7345 - val_loss: 0.6477 - val_accuracy: 0.7236\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5943 - accuracy: 0.7420 - val_loss: 0.6413 - val_accuracy: 0.7271\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5875 - accuracy: 0.7455 - val_loss: 0.6457 - val_accuracy: 0.7284\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.7463 - val_loss: 0.6403 - val_accuracy: 0.7304\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.7470 - val_loss: 0.6387 - val_accuracy: 0.7320\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7470 - val_loss: 0.6507 - val_accuracy: 0.7287\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.7458 - val_loss: 0.6456 - val_accuracy: 0.7330\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.7512 - val_loss: 0.6283 - val_accuracy: 0.7385\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.7567 - val_loss: 0.6351 - val_accuracy: 0.7356\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5702 - accuracy: 0.7549 - val_loss: 0.6303 - val_accuracy: 0.7369\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5710 - accuracy: 0.7495 - val_loss: 0.6276 - val_accuracy: 0.7411\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5689 - accuracy: 0.7576 - val_loss: 0.6389 - val_accuracy: 0.7375\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5650 - accuracy: 0.7552 - val_loss: 0.6302 - val_accuracy: 0.7343\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.7629 - val_loss: 0.6215 - val_accuracy: 0.7430\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5634 - accuracy: 0.7592 - val_loss: 0.6185 - val_accuracy: 0.7433\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5553 - accuracy: 0.7622 - val_loss: 0.6217 - val_accuracy: 0.7417\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5543 - accuracy: 0.7563 - val_loss: 0.6180 - val_accuracy: 0.7411\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5542 - accuracy: 0.7645 - val_loss: 0.6176 - val_accuracy: 0.7485\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5601 - accuracy: 0.7537 - val_loss: 0.6162 - val_accuracy: 0.7433\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5487 - accuracy: 0.7624 - val_loss: 0.6107 - val_accuracy: 0.7469\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7641 - val_loss: 0.6282 - val_accuracy: 0.7320\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7644 - val_loss: 0.6190 - val_accuracy: 0.7466\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7640 - val_loss: 0.6147 - val_accuracy: 0.7463\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7769 - val_loss: 0.6009 - val_accuracy: 0.7485\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7719 - val_loss: 0.6098 - val_accuracy: 0.7524\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7679 - val_loss: 0.6073 - val_accuracy: 0.7531\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7737 - val_loss: 0.5965 - val_accuracy: 0.7524\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5333 - accuracy: 0.7707 - val_loss: 0.6031 - val_accuracy: 0.7498\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5385 - accuracy: 0.7690 - val_loss: 0.5948 - val_accuracy: 0.7502\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7694 - val_loss: 0.5982 - val_accuracy: 0.7583\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7723 - val_loss: 0.5899 - val_accuracy: 0.7492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25d3962e4f0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]\n",
    "\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), \n",
    "          epochs=100, batch_size=500, callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=3, n_neurons=100, learning_rate=3e-3, act=\"relu\"):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=62))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=act))\n",
    "    model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 666us/step - loss: 0.7213 - accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 720us/step - loss: 0.7062 - accuracy: 0.6871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 613us/step - loss: 0.7594 - accuracy: 0.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 734us/step - loss: 1.1753 - accuracy: 0.4276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 661us/step - loss: 1.3629 - accuracy: 0.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 632us/step - loss: 1.0656 - accuracy: 0.4061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 707us/step - loss: 1.3766 - accuracy: 0.3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 667us/step - loss: 1.3714 - accuracy: 0.3292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 638us/step - loss: 1.3664 - accuracy: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 636us/step - loss: 0.7862 - accuracy: 0.6383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 603us/step - loss: 0.7814 - accuracy: 0.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 603us/step - loss: 0.7999 - accuracy: 0.6461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 668us/step - loss: 0.9064 - accuracy: 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 607us/step - loss: 0.9067 - accuracy: 0.6058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erich\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 632us/step - loss: 0.8886 - accuracy: 0.5881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x0000025D40019A60>,\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'learning_rate': (0.001, 0.01, 0.1),\n",
       "                                        'n_hidden': (1, 2, 3, 4, 5),\n",
       "                                        'n_neurons': (50, 55, 60, 65, 70, 75,\n",
       "                                                      80, 85, 90, 95, 100)})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "                \"n_hidden\": (1,2,3,4,5), #np.arange(1, 5), generates error because of a scikit bug\n",
    "                \"n_neurons\": (50,55,60,65,70,75,80,85,90,95,100), #np.arange(50, 100), generates error\n",
    "                \"learning_rate\": (0.001, 0.01, 0.1)\n",
    "                }\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_distribs, n_iter=5, cv=3)\n",
    "\n",
    "rnd_search_cv.fit(train_x, train_y, epochs=5, validation_data=(test_x, test_y), \n",
    "                  callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 95, 'n_hidden': 1, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nav_menu": {
   "height": "279px",
   "width": "309px"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
