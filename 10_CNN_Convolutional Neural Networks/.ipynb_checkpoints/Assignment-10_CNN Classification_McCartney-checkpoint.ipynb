{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - CNN Classification - McCartney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on Lego bricks. The data set contains rendered images of 16 different types of Lego bricks. This is an image classification task: build a model that can correctly identify lego bricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the LEGO folder on your computer (as part of the downloaded files). Use the **train** folder and build a model to predict the **category** of each image. Then, validate your model on the images in the **valid** folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint1: \n",
    "\n",
    "The images in the train and valid folders are 200x200 pixels. These are big images. I recommend resizing them while building your model. To do this, you can use the `target_size=(_,_)` parameter in the train and valid generator functions (you have to replace the _ with the dimensions you want: e.g., (32,32)). The images will be resized to whatever you enter in place of underscores while the generators are reading the images from the folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hint2: \n",
    "\n",
    "Training can take a long time if you don't have a powerful CPU. So, reduce the image sizes using the readers, create a shallow network, and keep the number of epochs small. Though, try to see if you can build models with more than 60% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6379 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Data Generator manipulates and \"augments\" images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# Directory Iterator reads images from a directory\n",
    "\n",
    "train_data = DirectoryIterator(\n",
    "    directory=\"LEGO/train\",\n",
    "    image_data_generator = train_datagen,\n",
    "    target_size=(16,16),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1555 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_data = DirectoryIterator(\n",
    "    directory=\"LEGO/valid\",\n",
    "    image_data_generator = valid_datagen,\n",
    "    target_size=(16,16),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 35,232\n",
      "Trainable params: 35,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "                 input_shape=(16,16,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 98/100 [============================>.] - ETA: 0s - loss: 2.7788 - accuracy: 0.0594WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 4s 32ms/step - loss: 2.7789 - accuracy: 0.0582 - val_loss: 2.7719 - val_accuracy: 0.0643\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 2.7746 - accuracy: 0.0610\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 2.7745 - accuracy: 0.0613\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 2s 22ms/step - loss: 2.7738 - accuracy: 0.0579\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 2s 21ms/step - loss: 2.7740 - accuracy: 0.0623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x230c86bc9d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_data,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=valid_data,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x230cb901730>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = load_img(\"LEGO/valid/3003 Brick 2x2/0021.png\",\n",
    "               color_mode='rgb',\n",
    "               target_size=(16,16)\n",
    "              )\n",
    "\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0647119 , 0.06307745, 0.05365559, 0.06411253, 0.0642253 ,\n",
       "        0.06070195, 0.06377913, 0.05888275, 0.05913322, 0.0661101 ,\n",
       "        0.06805654, 0.06250016, 0.06302314, 0.06886139, 0.06059277,\n",
       "        0.0585761 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the image to array\n",
    "single_image = img_to_array(img)\n",
    "\n",
    "#Also divide the image values by 255 to normalize\n",
    "img_rank4 = np.expand_dims(single_image/255, axis=0)\n",
    "\n",
    "model.predict(img_rank4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06, 0.06, 0.05, 0.06, 0.06, 0.06, 0.06, 0.06, 0.06, 0.07, 0.07,\n",
       "        0.06, 0.06, 0.07, 0.06, 0.06]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(img_rank4),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict the class directly using the following function:\n",
    "\n",
    "np.argmax(model.predict(img_rank4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11214 Bush 3M friction with Cross axle': 0,\n",
       " '18651 Cross Axle 2M with Snap friction': 1,\n",
       " '2357 Brick corner 1x2x2': 2,\n",
       " '3003 Brick 2x2': 3,\n",
       " '3004 Brick 1x2': 4,\n",
       " '3005 Brick 1x1': 5,\n",
       " '3022 Plate 2x2': 6,\n",
       " '3023 Plate 1x2': 7,\n",
       " '3024 Plate 1x1': 8,\n",
       " '3040 Roof Tile 1x2x45deg': 9,\n",
       " '3069 Flat Tile 1x2': 10,\n",
       " '32123 half Bush': 11,\n",
       " '3673 Peg 2M': 12,\n",
       " '3713 Bush for Cross Axle': 13,\n",
       " '3794 Plate 1X2 with 1 Knob': 14,\n",
       " '6632 Technic Lever 3M': 15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class labels from the train_generator:\n",
    "\n",
    "label_map = (train_data.class_indices)\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3713 Bush for Cross Axle'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class label of the prediction:\n",
    "\n",
    "list(label_map.keys())[np.argmax(model.predict(img_rank4), axis=-1)[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
