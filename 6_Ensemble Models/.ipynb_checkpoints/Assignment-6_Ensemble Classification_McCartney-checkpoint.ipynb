{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Ensemble Classification - McCartney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on underage drinking. The data set contains data about high school students. Each row represents a single student. The columns include the characteristics of deidentified students. This is a binary classification task: predict whether a student drinks alcohol or not (this is the **Alc** column: 1=Yes, 0=No). This is an important prediction task to detect underage drinking and deploy intervention techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Alcohol - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **alcohol.csv** data set and build a model to predict **Alc**. Build (at least) the models required below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data\n",
    "## Also, perform feature engineering: create one new variable from existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(31484443)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>gender</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences gender  alc  \n",
       "0       5         2      M    1  \n",
       "1       3         9      M    1  \n",
       "2       5         0      F    0  \n",
       "3       3        10      F    0  \n",
       "4       5         2      M    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data set\n",
    "#We will predict the \"readmitted\" value in the data set:\n",
    "\n",
    "alcohol = pd.read_csv(\"alcohol.csv\")\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34000, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "health        0\n",
       "absences      0\n",
       "gender        0\n",
       "alc           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "      <td>34000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.304588</td>\n",
       "      <td>3.473353</td>\n",
       "      <td>2.945853</td>\n",
       "      <td>1.174176</td>\n",
       "      <td>2.153029</td>\n",
       "      <td>0.027235</td>\n",
       "      <td>4.126676</td>\n",
       "      <td>3.222618</td>\n",
       "      <td>3.145059</td>\n",
       "      <td>3.413147</td>\n",
       "      <td>4.848206</td>\n",
       "      <td>0.477735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.051145</td>\n",
       "      <td>1.573011</td>\n",
       "      <td>1.158278</td>\n",
       "      <td>0.860493</td>\n",
       "      <td>0.849178</td>\n",
       "      <td>0.258664</td>\n",
       "      <td>0.829495</td>\n",
       "      <td>0.747163</td>\n",
       "      <td>1.080084</td>\n",
       "      <td>1.263086</td>\n",
       "      <td>5.447010</td>\n",
       "      <td>0.499511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age          Medu          Fedu    traveltime     studytime  \\\n",
       "count  34000.000000  34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean      16.304588      3.473353      2.945853      1.174176      2.153029   \n",
       "std        1.051145      1.573011      1.158278      0.860493      0.849178   \n",
       "min       13.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       16.000000      2.000000      2.000000      1.000000      2.000000   \n",
       "50%       16.000000      4.000000      3.000000      1.000000      2.000000   \n",
       "75%       17.000000      5.000000      4.000000      2.000000      3.000000   \n",
       "max       21.000000      8.000000      7.000000      7.000000      5.000000   \n",
       "\n",
       "           failures        famrel      freetime         goout        health  \\\n",
       "count  34000.000000  34000.000000  34000.000000  34000.000000  34000.000000   \n",
       "mean       0.027235      4.126676      3.222618      3.145059      3.413147   \n",
       "std        0.258664      0.829495      0.747163      1.080084      1.263086   \n",
       "min        0.000000      1.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      4.000000      3.000000      2.000000      3.000000   \n",
       "50%        0.000000      4.000000      3.000000      3.000000      3.000000   \n",
       "75%        0.000000      5.000000      4.000000      4.000000      4.000000   \n",
       "max        7.000000      6.000000      6.000000      6.000000      8.000000   \n",
       "\n",
       "           absences           alc  \n",
       "count  34000.000000  34000.000000  \n",
       "mean       4.848206      0.477735  \n",
       "std        5.447010      0.499511  \n",
       "min        0.000000      0.000000  \n",
       "25%        1.000000      0.000000  \n",
       "50%        3.000000      0.000000  \n",
       "75%        7.000000      1.000000  \n",
       "max       37.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(alcohol, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't use the following columns in this tutorial, because they are not for binary classification tasks\n",
    "\n",
    "train = train_set.drop([], axis=1)\n",
    "test = test_set.drop([], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target variable and input variables\n",
    "\n",
    "train_y = train['alc']\n",
    "test_y = test['alc']\n",
    "\n",
    "train_inputs = train.drop(['alc'], axis=1)\n",
    "test_inputs = test.drop(['alc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16838     5\n",
       "5962      6\n",
       "24633     5\n",
       "26949     6\n",
       "24846     0\n",
       "         ..\n",
       "19338     5\n",
       "4349      0\n",
       "9055     12\n",
       "7981      0\n",
       "643      18\n",
       "Name: absences, Length: 23800, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['absences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4498\n",
       "1     3823\n",
       "2     3105\n",
       "3     2113\n",
       "4     1486\n",
       "5     1250\n",
       "6      876\n",
       "7      741\n",
       "9      716\n",
       "8      702\n",
       "10     665\n",
       "11     581\n",
       "12     548\n",
       "13     475\n",
       "14     403\n",
       "15     365\n",
       "16     312\n",
       "17     221\n",
       "18     199\n",
       "19     170\n",
       "20     123\n",
       "21     102\n",
       "22      86\n",
       "23      67\n",
       "24      56\n",
       "25      36\n",
       "26      18\n",
       "28      17\n",
       "27      16\n",
       "29       8\n",
       "32       6\n",
       "30       5\n",
       "31       5\n",
       "33       3\n",
       "35       2\n",
       "36       1\n",
       "Name: absences, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['absences'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set['absences'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "\n",
    "def new_col(df):\n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    df1['absences_binned'] = pd.cut(df1['absences'],\n",
    "                                       bins=[0,0.5,1,5,10,20,10000],  #bins=[exclusive, inclusive]\n",
    "                                       labels=False, \n",
    "                                       include_lowest=True,\n",
    "                                       ordered=True)\n",
    "    \n",
    "#     You can also do this if you want categorical values:    \n",
    "#     df1['num_reviews_binned'] = pd.cut(df1['number_of_reviews'],\n",
    "#                                        bins=[0,0.5,1,5,15,50,10000], \n",
    "#                                        labels=['None','Very few','Few','Medium','Many','Too many'], \n",
    "#                                        include_lowest=True,\n",
    "#                                        ordered=False)\n",
    "\n",
    "    \n",
    "    return df1[['absences_binned']]\n",
    "    # You can use this to check whether the calculation is made correctly:\n",
    "    #return df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absences_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16838</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5962</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24633</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26949</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24846</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19338</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7981</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23800 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       absences_binned\n",
       "16838                2\n",
       "5962                 3\n",
       "24633                2\n",
       "26949                3\n",
       "24846                0\n",
       "...                ...\n",
       "19338                2\n",
       "4349                 0\n",
       "9055                 4\n",
       "7981                 0\n",
       "643                  4\n",
       "\n",
       "[23800 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's test the new function:\n",
    "\n",
    "# Send train set to the function we created\n",
    "new_col(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "Medu           int64\n",
       "Fedu           int64\n",
       "traveltime     int64\n",
       "studytime      int64\n",
       "failures       int64\n",
       "famrel         int64\n",
       "freetime       int64\n",
       "goout          int64\n",
       "health         int64\n",
       "absences       int64\n",
       "gender        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the columns\n",
    "\n",
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'health',\n",
       " 'absences']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng_columns = ['absences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        #('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, feat_eng_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.61535704,  0.33359512,  0.91018794, ...,  1.        ,\n",
       "         0.        ,  0.03257509],\n",
       "       [-0.28826237, -0.301113  ,  0.04652185, ...,  0.        ,\n",
       "         1.        ,  0.77732751],\n",
       "       [ 0.66354734, -2.20523736, -1.68081034, ...,  0.        ,\n",
       "         1.        ,  0.03257509],\n",
       "       ...,\n",
       "       [-0.28826237, -0.93582112,  0.04652185, ...,  0.        ,\n",
       "         1.        ,  1.52207992],\n",
       "       [-2.19188178,  0.33359512,  0.91018794, ...,  1.        ,\n",
       "         0.        , -1.45692973],\n",
       "       [ 0.66354734, -0.93582112, -1.68081034, ...,  1.        ,\n",
       "         0.        ,  1.52207992]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.24007207, -0.301113  ,  0.91018794, ...,  1.        ,\n",
       "         0.        ,  0.03257509],\n",
       "       [-1.24007207,  0.96830324,  0.91018794, ...,  1.        ,\n",
       "         0.        ,  0.03257509],\n",
       "       [-2.19188178,  1.60301136,  2.63752013, ...,  0.        ,\n",
       "         1.        ,  0.03257509],\n",
       "       ...,\n",
       "       [ 1.61535704,  0.33359512,  0.04652185, ...,  0.        ,\n",
       "         1.        ,  1.52207992],\n",
       "       [ 1.61535704,  0.33359512,  0.04652185, ...,  0.        ,\n",
       "         1.        ,  1.52207992],\n",
       "       [-0.28826237,  0.96830324,  0.91018794, ...,  1.        ,\n",
       "         0.        ,  0.03257509]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 14)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.522983\n",
       "1    0.477017\n",
       "Name: alc, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()/len(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=6)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=10, max_iter=1000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('sgd', SGDClassifier(max_iter=10000))])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=6)\n",
    "log_clf = LogisticRegression(multi_class='multinomial', solver = 'lbfgs', C=10, max_iter=1000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf), \n",
    "                        ('sgd', sgd_clf)],\n",
    "            voting='hard')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8232773109243697\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8223529411764706\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4434,  876],\n",
       "       [ 936, 3954]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Test acc= 0.7870588235294118\n",
      "LogisticRegression Test acc= 0.8211764705882353\n",
      "SGDClassifier Test acc= 0.8182352941176471\n",
      "VotingClassifier Test acc= 0.8202941176470588\n"
     ]
    }
   ],
   "source": [
    "for clf in (dtree_clf, log_clf, sgd_clf, voting_clf):\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "    test_y_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, 'Test acc=', accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=6)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=10, max_iter=1000,\n",
       "                                                 multi_class='multinomial'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each model should have predict_proba() function. Otherwise, you can't use it for soft voting\n",
    "#We can't use sgd, because it doesn't have predict_proba() function.\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf)],\n",
    "            voting='soft')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8210504201680672\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.817156862745098\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SGDClassifier(), max_samples=1000,\n",
       "                  n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "\n",
    "#If you want to do pasting, change \"bootstrap=False\"\n",
    "#n_jobs=-1 means use all CPU cores\n",
    "#bagging automatically performs soft voting\n",
    "\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, \n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8217226890756303\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8208823529411765\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8216806722689075"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Out of Bag Evaluation\n",
    "\n",
    "#Use the oob_score variable:\n",
    "bag_clf = BaggingClassifier( \n",
    "            SGDClassifier(), n_estimators=50, \n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1, oob_score=True) \n",
    "\n",
    "bag_clf.fit(train_x, train_y)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=50, n_jobs=-1) \n",
    "# reduce estimators to save cpu power, inc estimators didn't improve model in this example\n",
    "\n",
    "rnd_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9823109243697479\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = rnd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8047058823529412\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = rnd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0930257 , 0.17395462, 0.08746379, 0.08459732, 0.11992225,\n",
       "       0.00234148, 0.05918143, 0.04619204, 0.08037192, 0.08162529,\n",
       "       0.09512513, 0.01648881, 0.01661469, 0.04309553])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09, 0.17, 0.09, 0.08, 0.12, 0.  , 0.06, 0.05, 0.08, 0.08, 0.1 ,\n",
       "       0.02, 0.02, 0.04])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Round to two decimals\n",
    "np.round(rnd_clf.feature_importances_,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.1, n_estimators=500)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "#Create Adapative Boosting with Decision Stumps (depth=1)\n",
    "ada_clf = AdaBoostClassifier( \n",
    "            DecisionTreeClassifier(max_depth=1), n_estimators=500, \n",
    "            algorithm=\"SAMME.R\", learning_rate=0.1) \n",
    "\n",
    "ada_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8214705882352941\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = ada_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8195098039215686\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = ada_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use GradientBoosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=2, n_estimators=100, learning_rate=0.1) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.819327731092437\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.815\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, subsample=0.75)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train on 75% of the sample only\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=2, n_estimators=100, \n",
    "                                   learning_rate=0.1, subsample=0.75) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8184033613445378\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8151960784313725\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Briefly answer the following questions: (2 points) \n",
    "1) Which model performs the best (and why)?<br>\n",
    "2) What is the baseline?<br>\n",
    "3) Does the best model perform better than the baseline (and why)?<br>\n",
    "4) Does the best model exhibit any overfitting; what did you do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Hard voting performe best with 82.12% test accuracy without exceeding train accuracy<br>\n",
    "2- 52.29% accuracy<br>\n",
    "3- Yes hard voting accuracy is 82.12% accurate compared to 47.79% for the baseline<br>\n",
    "4- No over fitting present with the test accuracy just slightly below the train accuracy<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
