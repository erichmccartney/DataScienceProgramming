{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Autoencoder - McCartney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set contains data about patients with and without heart problems. Each row represents a single patient. There two files: heart-normal (contains patients without any heart problems) and heart_anomaly (contains patients with heart problems). This is an anomaly detection task: build an autoencoder on normal patients to identify anomalous observations. You cannot do supervised learning, because there are only 20 anomalous observations - which is not enough to build a binary classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Heart - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **heart-normal.csv** data set to train an autoencoder on healthy (i.e., normal) patients. Then, use the observations in **heart-anomaly.csv** data set to check whether the autoencoder can successfully detect patients who have a heart anomaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_anomaly = pd.read_csv(\"heart-anomaly.csv\")\n",
    "\n",
    "heart_normal = pd.read_csv(\"heart-normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_normal.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_anomaly.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_normal.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = heart_normal.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = heart_normal.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "binary_columns = ['sex', 'fbs', 'exang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "categorical_columns = ['thal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful: numerical columns already includes the binary columns,\n",
    "# So, we need to remove the binary columns from numerical columns.\n",
    "\n",
    "for col in categorical_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'fbs', 'exang']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thal']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=9999)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        remainder='passthrough')\n",
    "    \n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.10306652,  1.71093264,  0.97372481, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.62754823,  0.65755993,  0.04323489, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.20745366, -0.39581278,  0.04323489, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.20745366, -0.39581278, -0.57709173, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.52252459,  0.65755993,  0.53949618, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.52252459,  0.65755993,  0.53949618, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "\n",
    "normal_x = preprocessor.fit_transform(heart_normal)\n",
    "\n",
    "normal_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5231611 , -1.44918549,  1.90421473,  0.81980549, -1.18012347,\n",
       "        -2.6400108 ,  1.17814884, -1.0035591 ,  3.1150997 ,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 1.5231611 , -1.44918549, -0.57709173, -0.24780329, -1.18012347,\n",
       "        -1.54145941,  2.59146023, -1.0035591 ,  1.93351016,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.99804287, -1.44918549,  0.6635615 ,  0.48266588, -1.18012347,\n",
       "         0.08021169,  3.87628877, -2.69322494,  1.93351016,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 1.10306652, -1.44918549,  0.04323489,  0.22044617, -1.18012347,\n",
       "        -0.59984393,  1.04966598, -1.0035591 ,  0.75192062,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.05283008, -1.44918549,  0.6635615 , -0.73478274, -1.18012347,\n",
       "        -0.18134817,  3.2338745 , -2.69322494, -0.42966892,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [ 0.36790101,  0.65755993,  0.04323489,  0.25790613, -1.18012347,\n",
       "        -0.86140379,  0.02180315, -1.0035591 ,  0.75192062,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [-0.47228815, -0.39581278, -1.19741835, -0.24780329,  0.80681911,\n",
       "         0.49870746,  0.53573457, -2.69322494, -0.42966892,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.5779483 , -0.39581278, -0.57709173,  0.78234554, -1.18012347,\n",
       "         0.08021169,  1.5635974 , -1.0035591 , -0.42966892,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.5779483 ,  0.65755993,  0.16730021, -0.34145319, -1.18012347,\n",
       "         0.76026731,  3.36235735,  0.68610673,  1.93351016,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.78799559, -1.44918549,  0.04323489, -0.67859281, -1.18012347,\n",
       "        -1.38452349,  2.33449452, -1.0035591 ,  1.93351016,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [-1.3124773 , -1.44918549, -1.19741835, -1.40906198, -1.18012347,\n",
       "        -2.32613897,  1.8205631 , -1.0035591 , -0.42966892,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.78799559, -1.44918549, -0.76318971, -0.22907332,  0.80681911,\n",
       "         0.08021169,  1.04966598,  0.68610673,  1.93351016,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ],\n",
       "       [ 1.20809016,  0.65755993,  0.6635615 ,  1.73757445,  0.80681911,\n",
       "        -0.02441225, -0.74909397,  0.68610673, -0.42966892,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.99740637, -1.44918549, -0.57709173, -1.22176219, -1.18012347,\n",
       "        -2.01226714,  2.46297737, -1.0035591 , -0.42966892,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.47292465, -1.44918549,  1.28388812,  0.63250571, -1.18012347,\n",
       "        -2.43076291,  0.02180315, -1.0035591 ,  0.75192062,  0.        ,\n",
       "         1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.26287736, -1.44918549,  0.16730021,  2.07471407,  0.80681911,\n",
       "        -1.38452349,  0.79270027, -1.0035591 ,  0.75192062,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 1.31311381, -1.44918549,  1.28388812, -0.32272321, -1.18012347,\n",
       "        -2.32613897,  0.53573457, -1.0035591 ,  3.1150997 ,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.89301923, -1.44918549,  0.04323489,  1.64392456, -1.18012347,\n",
       "         0.55101943, -0.74909397,  0.68610673, -0.42966892,  0.        ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.5779483 ,  0.65755993, -1.07335302, -0.22907332, -1.18012347,\n",
       "         0.34177154,  2.46297737, -1.0035591 ,  0.75192062,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.26224086, -1.44918549,  1.28388812,  0.01441641, -1.18012347,\n",
       "        -1.59377138,  2.59146023, -1.0035591 , -0.42966892,  0.        ,\n",
       "         0.        ,  0.        ,  1.        ,  1.        ,  0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "anomaly_x = preprocessor.transform(airbnb_anomaly)\n",
    "\n",
    "anomaly_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 55)                935       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2800      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 55)                2805      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                896       \n",
      "=================================================================\n",
      "Total params: 7,436\n",
      "Trainable params: 7,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#Encoder\n",
    "model.add(keras.layers.InputLayer(input_shape=normal_x.shape[1]))\n",
    "model.add(keras.layers.Dense(55, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "\n",
    "#Decoder\n",
    "model.add(keras.layers.Dense(55, activation='relu'))\n",
    "model.add(keras.layers.Dense(normal_x.shape[1], activation=None))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(loss='mse', optimizer='Nadam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.7557 - mean_squared_error: 0.7557 - val_loss: 0.7289 - val_mean_squared_error: 0.7289\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.7257 - mean_squared_error: 0.7257 - val_loss: 0.7074 - val_mean_squared_error: 0.7074\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.7040 - mean_squared_error: 0.7040 - val_loss: 0.6869 - val_mean_squared_error: 0.6869\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6838 - mean_squared_error: 0.6838 - val_loss: 0.6678 - val_mean_squared_error: 0.6678\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.6646 - mean_squared_error: 0.6646 - val_loss: 0.6493 - val_mean_squared_error: 0.6493\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6461 - mean_squared_error: 0.6461 - val_loss: 0.6309 - val_mean_squared_error: 0.6309\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6281 - mean_squared_error: 0.6281 - val_loss: 0.6130 - val_mean_squared_error: 0.6130\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6100 - mean_squared_error: 0.6100 - val_loss: 0.5949 - val_mean_squared_error: 0.5949\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.5921 - mean_squared_error: 0.5921 - val_loss: 0.5768 - val_mean_squared_error: 0.5768\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5740 - mean_squared_error: 0.5740 - val_loss: 0.5582 - val_mean_squared_error: 0.5582\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5550 - mean_squared_error: 0.5550 - val_loss: 0.5386 - val_mean_squared_error: 0.5386\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.5352 - mean_squared_error: 0.5352 - val_loss: 0.5182 - val_mean_squared_error: 0.5182\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5149 - mean_squared_error: 0.5149 - val_loss: 0.4971 - val_mean_squared_error: 0.4971\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4936 - mean_squared_error: 0.4936 - val_loss: 0.4752 - val_mean_squared_error: 0.4752\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4715 - mean_squared_error: 0.4715 - val_loss: 0.4520 - val_mean_squared_error: 0.4520\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4482 - mean_squared_error: 0.4482 - val_loss: 0.4281 - val_mean_squared_error: 0.4281\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.4243 - mean_squared_error: 0.4243 - val_loss: 0.4039 - val_mean_squared_error: 0.4039\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3999 - mean_squared_error: 0.3999 - val_loss: 0.3794 - val_mean_squared_error: 0.3794\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.3555 - val_mean_squared_error: 0.3555\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.3521 - mean_squared_error: 0.3521 - val_loss: 0.3319 - val_mean_squared_error: 0.3319\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.3079 - val_mean_squared_error: 0.3079\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3045 - mean_squared_error: 0.3045 - val_loss: 0.2853 - val_mean_squared_error: 0.2853\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2821 - mean_squared_error: 0.2821 - val_loss: 0.2640 - val_mean_squared_error: 0.2640\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2606 - mean_squared_error: 0.2606 - val_loss: 0.2438 - val_mean_squared_error: 0.2438\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.2408 - mean_squared_error: 0.2408 - val_loss: 0.2251 - val_mean_squared_error: 0.2251\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2227 - mean_squared_error: 0.2227 - val_loss: 0.2082 - val_mean_squared_error: 0.2082\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2062 - mean_squared_error: 0.2062 - val_loss: 0.1929 - val_mean_squared_error: 0.1929\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1912 - mean_squared_error: 0.1912 - val_loss: 0.1792 - val_mean_squared_error: 0.1792\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1780 - mean_squared_error: 0.1780 - val_loss: 0.1667 - val_mean_squared_error: 0.1667\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1651 - mean_squared_error: 0.1651 - val_loss: 0.1549 - val_mean_squared_error: 0.1549\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.1541 - mean_squared_error: 0.1541 - val_loss: 0.1452 - val_mean_squared_error: 0.1452\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1439 - mean_squared_error: 0.1439 - val_loss: 0.1360 - val_mean_squared_error: 0.1360\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1346 - mean_squared_error: 0.1346 - val_loss: 0.1269 - val_mean_squared_error: 0.1269\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1263 - mean_squared_error: 0.1263 - val_loss: 0.1195 - val_mean_squared_error: 0.1195\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.1190 - mean_squared_error: 0.1190 - val_loss: 0.1125 - val_mean_squared_error: 0.1125\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1121 - mean_squared_error: 0.1121 - val_loss: 0.1064 - val_mean_squared_error: 0.1064\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1067 - mean_squared_error: 0.1067 - val_loss: 0.1015 - val_mean_squared_error: 0.1015\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1009 - mean_squared_error: 0.1009 - val_loss: 0.0956 - val_mean_squared_error: 0.0956\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0954 - mean_squared_error: 0.0954 - val_loss: 0.0909 - val_mean_squared_error: 0.0909\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0912 - mean_squared_error: 0.0912 - val_loss: 0.0868 - val_mean_squared_error: 0.0868\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0862 - mean_squared_error: 0.0862 - val_loss: 0.0825 - val_mean_squared_error: 0.0825\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0821 - mean_squared_error: 0.0821 - val_loss: 0.0790 - val_mean_squared_error: 0.0790\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0794 - mean_squared_error: 0.0794 - val_loss: 0.0771 - val_mean_squared_error: 0.0771\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0758 - mean_squared_error: 0.0758 - val_loss: 0.0727 - val_mean_squared_error: 0.0727\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0725 - mean_squared_error: 0.0725 - val_loss: 0.0697 - val_mean_squared_error: 0.0697\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0699 - mean_squared_error: 0.0699 - val_loss: 0.0680 - val_mean_squared_error: 0.0680\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0681 - mean_squared_error: 0.0681 - val_loss: 0.0657 - val_mean_squared_error: 0.0657\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0665 - mean_squared_error: 0.0665 - val_loss: 0.0635 - val_mean_squared_error: 0.0635\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0633 - mean_squared_error: 0.0633 - val_loss: 0.0601 - val_mean_squared_error: 0.0601\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 0.0583 - val_mean_squared_error: 0.0583\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0584 - mean_squared_error: 0.0584 - val_loss: 0.0565 - val_mean_squared_error: 0.0565\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0569 - mean_squared_error: 0.0569 - val_loss: 0.0553 - val_mean_squared_error: 0.0553\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0556 - mean_squared_error: 0.0556 - val_loss: 0.0541 - val_mean_squared_error: 0.0541\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0538 - mean_squared_error: 0.0538 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0520 - mean_squared_error: 0.0520 - val_loss: 0.0513 - val_mean_squared_error: 0.0513\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - val_loss: 0.0478 - val_mean_squared_error: 0.0478\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0464 - val_mean_squared_error: 0.0464\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0452 - val_mean_squared_error: 0.0452\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0453 - mean_squared_error: 0.0453 - val_loss: 0.0450 - val_mean_squared_error: 0.0450\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0456 - mean_squared_error: 0.0456 - val_loss: 0.0432 - val_mean_squared_error: 0.0432\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0436 - mean_squared_error: 0.0436 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - val_loss: 0.0393 - val_mean_squared_error: 0.0393\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0391 - mean_squared_error: 0.0391 - val_loss: 0.0379 - val_mean_squared_error: 0.0379\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0372 - val_mean_squared_error: 0.0372\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0368 - val_mean_squared_error: 0.0368\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0365 - val_mean_squared_error: 0.0365\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0349 - val_mean_squared_error: 0.0349\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0340 - val_mean_squared_error: 0.0340\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0340 - mean_squared_error: 0.0340 - val_loss: 0.0329 - val_mean_squared_error: 0.0329\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0331 - mean_squared_error: 0.0331 - val_loss: 0.0332 - val_mean_squared_error: 0.0332\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0319 - val_mean_squared_error: 0.0319\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0300 - val_mean_squared_error: 0.0300\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0302 - mean_squared_error: 0.0302 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0307 - mean_squared_error: 0.0307 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0297 - mean_squared_error: 0.0297 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0279 - val_mean_squared_error: 0.0279\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0278 - val_mean_squared_error: 0.0278\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0266 - val_mean_squared_error: 0.0266\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0272 - val_mean_squared_error: 0.0272\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0279 - mean_squared_error: 0.0279 - val_loss: 0.0288 - val_mean_squared_error: 0.0288\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0288 - mean_squared_error: 0.0288 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0296 - val_mean_squared_error: 0.0296\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0289 - mean_squared_error: 0.0289 - val_loss: 0.0263 - val_mean_squared_error: 0.0263\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0243 - val_mean_squared_error: 0.0243\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0240 - val_mean_squared_error: 0.0240\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0228 - val_mean_squared_error: 0.0228\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0228 - mean_squared_error: 0.0228 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.0207 - mean_squared_error: 0.0207 - val_loss: 0.0201 - val_mean_squared_error: 0.0201\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2613b1df610>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(normal_x, normal_x, \n",
    "          validation_data = (normal_x, normal_x),\n",
    "          epochs=100, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 685us/step - loss: 0.0182 - mean_squared_error: 0.0182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.01818540319800377, 0.01818540319800377]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(normal_x, normal_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 602us/step - loss: 0.0182 - mean_squared_error: 0.0182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18.18540319800377"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiply by 1000 to make sense of the error term:\n",
    "\n",
    "model.evaluate(normal_x, normal_x)[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0800 - mean_squared_error: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08003966510295868, 0.08003966510295868]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(anomaly_x, anomaly_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0800 - mean_squared_error: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80.03966510295868"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiply by 1000 to make sense of the error term:\n",
    "\n",
    "model.evaluate(anomaly_x, anomaly_x)[0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict first 20 in normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.881622319451544\n",
      "15.06441297281386\n",
      "20.101264290640785\n",
      "13.555628624686983\n",
      "10.580669087980551\n",
      "48.063486554558246\n",
      "11.440084221048151\n",
      "19.54098287855321\n",
      "19.398707572248238\n",
      "11.983455222502055\n",
      "10.296929725230799\n",
      "8.946287488738028\n",
      "4.349599301704395\n",
      "21.088141437297857\n",
      "24.60331630215143\n",
      "2.8384562524692183\n",
      "13.49065907741606\n",
      "17.461861053404984\n",
      "10.485419038714724\n",
      "22.787566941401327\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for i in range(0,20):\n",
    "    prediction = model.predict(normal_x[i:i+1])\n",
    "    print((mean_squared_error(normal_x[i:i+1], prediction))*1000)\n",
    "\n",
    "    \n",
    "#Error terms are multiplied by 1000 to make sense of the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all 20 in anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.80814779364759\n",
      "72.3301107634933\n",
      "128.14193937452788\n",
      "38.04292732918064\n",
      "77.80655766858357\n",
      "116.78861590808884\n",
      "70.91113204431538\n",
      "26.087085760191517\n",
      "161.4536023284414\n",
      "70.46701559032006\n",
      "104.1474409811993\n",
      "58.93828602061158\n",
      "56.17054187416331\n",
      "92.91841157838196\n",
      "105.27897816239779\n",
      "26.34827799836879\n",
      "123.39900754995524\n",
      "19.10632139301839\n",
      "90.36656127829009\n",
      "81.28217754177147\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    prediction = model.predict(anomaly_x[i:i+1])\n",
    "    print((mean_squared_error(anomaly_x[i:i+1], prediction))*1000)\n",
    "\n",
    "    \n",
    "#Error terms are multiplied by 1000 to make sense of the numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Provide a brief discussion (one-paragraph): can the model successfully detect patients with heart anomalies? If not, why? <br>\n",
    "Discuss any other relevant issues about your autoencoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, several error temrs less than mean however error significantly increased on anomonly data by a factor of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit (3 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GAN\n",
    "\n",
    "Build a GAN that can generate patients with **normal hearts**. Test the effectiveness of your GAN using the autoencoder you built earlier. Hint: when you send your newly generated data to the autoencoder, the error term should be small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Provide a brief discussion (one-paragraph): can the GAN generate patients with normal heart? If not, why? <br>\n",
    "Discuss any other relevant issues about your GAN. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
