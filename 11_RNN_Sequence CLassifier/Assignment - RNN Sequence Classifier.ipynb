{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - RNN Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 187 data points (columns) for each measurement. This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T187 are the values of a measurement on the timeline (there are 187 data points, or columns, in a single measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T187**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important note:\n",
    "\n",
    "Looks like the original length of the sequences were not the same in the data set. For example, one sequence (i.e., row) had 187 columns, while another one had 150 only. Therefore, the creators of the data set did a \"zero padding\". This means that they added zeros at end of each sequence to make them the same length. This way, all sequences (i.e., rows) were made to have 187 columns.\n",
    "\n",
    "If you don't account for the zero-padding, you will create biased models. To account for this, you can use the following as your first layer of your models:<br>\n",
    "`tf.keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs])`<br>\n",
    "(Of course, you need to enter your own values for n_steps and n_inputs). After you add this layer, continue with your other layers as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert as many cells as you need for data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model\n",
    "\n",
    "### Make sure to add the masking layer to the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model\n",
    "\n",
    "### Make sure to add the masking layer to this model too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Briefly answer the following questions: (2 points) \n",
    "1) Which model performs the best (and why)?<br>\n",
    "2) What is the baseline value?<br>\n",
    "3) Does the best model perform better than the baseline (and why)?<br>\n",
    "4) Does the best model exhibit any overfitting; what did you do about it?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
